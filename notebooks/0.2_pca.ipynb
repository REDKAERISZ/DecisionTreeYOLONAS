{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal component analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ckpt_name</th>\n",
       "      <th>training_hyperparams.cosine_final_lr_ratio</th>\n",
       "      <th>training_hyperparams.optimizer</th>\n",
       "      <th>training_hyperparams.batch_accumulate</th>\n",
       "      <th>training_hyperparams.phase_callbacks</th>\n",
       "      <th>training_hyperparams.initial_lr.backbone</th>\n",
       "      <th>training_hyperparams.initial_lr.default</th>\n",
       "      <th>training_hyperparams.schema.properties.initial_lr.anyOf</th>\n",
       "      <th>training_hyperparams.max_epochs</th>\n",
       "      <th>dataset_params.train_dataset_params</th>\n",
       "      <th>...</th>\n",
       "      <th>Precision@0.50:0.95</th>\n",
       "      <th>Recall@0.50:0.95</th>\n",
       "      <th>mAP@0.50:0.95</th>\n",
       "      <th>F1@0.50:0.95</th>\n",
       "      <th>AP@0.50:0.95_Mass</th>\n",
       "      <th>AP@0.50:0.95_Calcification</th>\n",
       "      <th>Best_score_threshold</th>\n",
       "      <th>Best_score_threshold_Mass</th>\n",
       "      <th>Best_score_threshold_Calcification</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUN_20240612_100027_359642</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>['&lt;super_gradients.training.utils.callbacks.ca...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[{'type': ['number', 'string', 'boolean', 'nul...</td>\n",
       "      <td>50</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'train/...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RUN_20240617_163510_293224</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>['&lt;super_gradients.training.utils.callbacks.ca...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[{'type': ['number', 'string', 'boolean', 'nul...</td>\n",
       "      <td>50</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'train/...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RUN_20240620_104658_182467</td>\n",
       "      <td>0.1</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>1</td>\n",
       "      <td>['&lt;super_gradients.training.utils.callbacks.ca...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[{'type': ['number', 'string', 'boolean', 'nul...</td>\n",
       "      <td>75</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'train/...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.076085</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.011509</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RUN_20240624_175224_278149</td>\n",
       "      <td>0.1</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>1</td>\n",
       "      <td>['&lt;super_gradients.training.utils.callbacks.ca...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[{'type': ['number', 'string', 'boolean', 'nul...</td>\n",
       "      <td>75</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'train/...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.119091</td>\n",
       "      <td>0.011001</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.021661</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RUN_20240625_113055_125920</td>\n",
       "      <td>0.1</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>1</td>\n",
       "      <td>['&lt;super_gradients.training.utils.callbacks.ca...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[{'type': ['number', 'string', 'boolean', 'nul...</td>\n",
       "      <td>100</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'train/...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.147835</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.031419</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ckpt_name  training_hyperparams.cosine_final_lr_ratio  \\\n",
       "0  RUN_20240612_100027_359642                                         0.1   \n",
       "1  RUN_20240617_163510_293224                                         0.1   \n",
       "2  RUN_20240620_104658_182467                                         0.1   \n",
       "3  RUN_20240624_175224_278149                                         0.1   \n",
       "4  RUN_20240625_113055_125920                                         0.1   \n",
       "\n",
       "  training_hyperparams.optimizer  training_hyperparams.batch_accumulate  \\\n",
       "0                           Adam                                      1   \n",
       "1                           Adam                                      1   \n",
       "2                          AdamW                                      1   \n",
       "3                          AdamW                                      1   \n",
       "4                          AdamW                                      1   \n",
       "\n",
       "                training_hyperparams.phase_callbacks  \\\n",
       "0  ['<super_gradients.training.utils.callbacks.ca...   \n",
       "1  ['<super_gradients.training.utils.callbacks.ca...   \n",
       "2  ['<super_gradients.training.utils.callbacks.ca...   \n",
       "3  ['<super_gradients.training.utils.callbacks.ca...   \n",
       "4  ['<super_gradients.training.utils.callbacks.ca...   \n",
       "\n",
       "   training_hyperparams.initial_lr.backbone  \\\n",
       "0                                      0.10   \n",
       "1                                      0.10   \n",
       "2                                      0.10   \n",
       "3                                      0.01   \n",
       "4                                      0.01   \n",
       "\n",
       "   training_hyperparams.initial_lr.default  \\\n",
       "0                                     0.10   \n",
       "1                                     0.10   \n",
       "2                                     0.10   \n",
       "3                                     0.01   \n",
       "4                                     0.01   \n",
       "\n",
       "  training_hyperparams.schema.properties.initial_lr.anyOf  \\\n",
       "0  [{'type': ['number', 'string', 'boolean', 'nul...        \n",
       "1  [{'type': ['number', 'string', 'boolean', 'nul...        \n",
       "2  [{'type': ['number', 'string', 'boolean', 'nul...        \n",
       "3  [{'type': ['number', 'string', 'boolean', 'nul...        \n",
       "4  [{'type': ['number', 'string', 'boolean', 'nul...        \n",
       "\n",
       "   training_hyperparams.max_epochs  \\\n",
       "0                               50   \n",
       "1                               50   \n",
       "2                               75   \n",
       "3                               75   \n",
       "4                              100   \n",
       "\n",
       "                 dataset_params.train_dataset_params  ...  \\\n",
       "0  {'data_dir': '../data/', 'images_dir': 'train/...  ...   \n",
       "1  {'data_dir': '../data/', 'images_dir': 'train/...  ...   \n",
       "2  {'data_dir': '../data/', 'images_dir': 'train/...  ...   \n",
       "3  {'data_dir': '../data/', 'images_dir': 'train/...  ...   \n",
       "4  {'data_dir': '../data/', 'images_dir': 'train/...  ...   \n",
       "\n",
       "   Precision@0.50:0.95  Recall@0.50:0.95 mAP@0.50:0.95 F1@0.50:0.95  \\\n",
       "0             0.000106          0.005259      0.000007     0.000182   \n",
       "1             0.000132          0.011994      0.000007     0.000235   \n",
       "2             0.000715          0.076085      0.005795     0.001406   \n",
       "3             0.001235          0.119091      0.011001     0.002431   \n",
       "4             0.001634          0.147835      0.015902     0.003215   \n",
       "\n",
       "   AP@0.50:0.95_Mass  AP@0.50:0.95_Calcification Best_score_threshold  \\\n",
       "0           0.000010                    0.000004                 0.11   \n",
       "1           0.000006                    0.000009                 0.11   \n",
       "2           0.000080                    0.011509                 0.25   \n",
       "3           0.000340                    0.021661                 0.25   \n",
       "4           0.000385                    0.031419                 0.25   \n",
       "\n",
       "   Best_score_threshold_Mass  Best_score_threshold_Calcification  Target  \n",
       "0                       0.11                                0.22       0  \n",
       "1                       0.11                                0.22       0  \n",
       "2                       0.10                                0.25       0  \n",
       "3                       0.18                                0.25       0  \n",
       "4                       0.18                                0.25       0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = \"../data/processed.csv\"\n",
    "dataset = pd.read_csv(raw_data)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop label columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since PCA is unsupervised, we don't want non-feature columns influencing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_hyperparams.cosine_final_lr_ratio</th>\n",
       "      <th>training_hyperparams.optimizer</th>\n",
       "      <th>training_hyperparams.batch_accumulate</th>\n",
       "      <th>training_hyperparams.phase_callbacks</th>\n",
       "      <th>training_hyperparams.initial_lr.backbone</th>\n",
       "      <th>training_hyperparams.initial_lr.default</th>\n",
       "      <th>training_hyperparams.schema.properties.initial_lr.anyOf</th>\n",
       "      <th>training_hyperparams.max_epochs</th>\n",
       "      <th>dataset_params.train_dataset_params</th>\n",
       "      <th>dataset_params.train_dataloader_params.batch_size</th>\n",
       "      <th>dataset_params.train_dataloader_params.num_workers</th>\n",
       "      <th>dataset_params.train_dataloader_params.collate_fn</th>\n",
       "      <th>dataset_params.valid_dataset_params</th>\n",
       "      <th>dataset_params.valid_dataloader_params.batch_size</th>\n",
       "      <th>dataset_params.valid_dataloader_params.num_workers</th>\n",
       "      <th>dataset_params.valid_dataloader_params.collate_fn</th>\n",
       "      <th>additional_log_items.initial_LR.backbone</th>\n",
       "      <th>additional_log_items.initial_LR.default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>['&lt;super_gradients.training.utils.callbacks.ca...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[{'type': ['number', 'string', 'boolean', 'nul...</td>\n",
       "      <td>50</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'train/...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;super_gradients.training.utils.collate_fn.det...</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'valid/...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;super_gradients.training.utils.collate_fn.det...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>['&lt;super_gradients.training.utils.callbacks.ca...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[{'type': ['number', 'string', 'boolean', 'nul...</td>\n",
       "      <td>50</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'train/...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;super_gradients.training.utils.collate_fn.det...</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'valid/...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;super_gradients.training.utils.collate_fn.det...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>1</td>\n",
       "      <td>['&lt;super_gradients.training.utils.callbacks.ca...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[{'type': ['number', 'string', 'boolean', 'nul...</td>\n",
       "      <td>75</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'train/...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>PPYoloECollateFN(random_resize_sizes=None, ran...</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'valid/...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>PPYoloECollateFN(random_resize_sizes=None, ran...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>1</td>\n",
       "      <td>['&lt;super_gradients.training.utils.callbacks.ca...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[{'type': ['number', 'string', 'boolean', 'nul...</td>\n",
       "      <td>75</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'train/...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>PPYoloECollateFN(random_resize_sizes=None, ran...</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'valid/...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>PPYoloECollateFN(random_resize_sizes=None, ran...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>1</td>\n",
       "      <td>['&lt;super_gradients.training.utils.callbacks.ca...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[{'type': ['number', 'string', 'boolean', 'nul...</td>\n",
       "      <td>100</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'train/...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>PPYoloECollateFN(random_resize_sizes=None, ran...</td>\n",
       "      <td>{'data_dir': '../data/', 'images_dir': 'valid/...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>PPYoloECollateFN(random_resize_sizes=None, ran...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   training_hyperparams.cosine_final_lr_ratio training_hyperparams.optimizer  \\\n",
       "0                                         0.1                           Adam   \n",
       "1                                         0.1                           Adam   \n",
       "2                                         0.1                          AdamW   \n",
       "3                                         0.1                          AdamW   \n",
       "4                                         0.1                          AdamW   \n",
       "\n",
       "   training_hyperparams.batch_accumulate  \\\n",
       "0                                      1   \n",
       "1                                      1   \n",
       "2                                      1   \n",
       "3                                      1   \n",
       "4                                      1   \n",
       "\n",
       "                training_hyperparams.phase_callbacks  \\\n",
       "0  ['<super_gradients.training.utils.callbacks.ca...   \n",
       "1  ['<super_gradients.training.utils.callbacks.ca...   \n",
       "2  ['<super_gradients.training.utils.callbacks.ca...   \n",
       "3  ['<super_gradients.training.utils.callbacks.ca...   \n",
       "4  ['<super_gradients.training.utils.callbacks.ca...   \n",
       "\n",
       "   training_hyperparams.initial_lr.backbone  \\\n",
       "0                                      0.10   \n",
       "1                                      0.10   \n",
       "2                                      0.10   \n",
       "3                                      0.01   \n",
       "4                                      0.01   \n",
       "\n",
       "   training_hyperparams.initial_lr.default  \\\n",
       "0                                     0.10   \n",
       "1                                     0.10   \n",
       "2                                     0.10   \n",
       "3                                     0.01   \n",
       "4                                     0.01   \n",
       "\n",
       "  training_hyperparams.schema.properties.initial_lr.anyOf  \\\n",
       "0  [{'type': ['number', 'string', 'boolean', 'nul...        \n",
       "1  [{'type': ['number', 'string', 'boolean', 'nul...        \n",
       "2  [{'type': ['number', 'string', 'boolean', 'nul...        \n",
       "3  [{'type': ['number', 'string', 'boolean', 'nul...        \n",
       "4  [{'type': ['number', 'string', 'boolean', 'nul...        \n",
       "\n",
       "   training_hyperparams.max_epochs  \\\n",
       "0                               50   \n",
       "1                               50   \n",
       "2                               75   \n",
       "3                               75   \n",
       "4                              100   \n",
       "\n",
       "                 dataset_params.train_dataset_params  \\\n",
       "0  {'data_dir': '../data/', 'images_dir': 'train/...   \n",
       "1  {'data_dir': '../data/', 'images_dir': 'train/...   \n",
       "2  {'data_dir': '../data/', 'images_dir': 'train/...   \n",
       "3  {'data_dir': '../data/', 'images_dir': 'train/...   \n",
       "4  {'data_dir': '../data/', 'images_dir': 'train/...   \n",
       "\n",
       "   dataset_params.train_dataloader_params.batch_size  \\\n",
       "0                                                 16   \n",
       "1                                                 16   \n",
       "2                                                 10   \n",
       "3                                                  4   \n",
       "4                                                  4   \n",
       "\n",
       "   dataset_params.train_dataloader_params.num_workers  \\\n",
       "0                                                  8    \n",
       "1                                                  8    \n",
       "2                                                  5    \n",
       "3                                                  2    \n",
       "4                                                  2    \n",
       "\n",
       "   dataset_params.train_dataloader_params.collate_fn  \\\n",
       "0  <super_gradients.training.utils.collate_fn.det...   \n",
       "1  <super_gradients.training.utils.collate_fn.det...   \n",
       "2  PPYoloECollateFN(random_resize_sizes=None, ran...   \n",
       "3  PPYoloECollateFN(random_resize_sizes=None, ran...   \n",
       "4  PPYoloECollateFN(random_resize_sizes=None, ran...   \n",
       "\n",
       "                 dataset_params.valid_dataset_params  \\\n",
       "0  {'data_dir': '../data/', 'images_dir': 'valid/...   \n",
       "1  {'data_dir': '../data/', 'images_dir': 'valid/...   \n",
       "2  {'data_dir': '../data/', 'images_dir': 'valid/...   \n",
       "3  {'data_dir': '../data/', 'images_dir': 'valid/...   \n",
       "4  {'data_dir': '../data/', 'images_dir': 'valid/...   \n",
       "\n",
       "   dataset_params.valid_dataloader_params.batch_size  \\\n",
       "0                                                 16   \n",
       "1                                                 16   \n",
       "2                                                 10   \n",
       "3                                                  4   \n",
       "4                                                  4   \n",
       "\n",
       "   dataset_params.valid_dataloader_params.num_workers  \\\n",
       "0                                                  8    \n",
       "1                                                  8    \n",
       "2                                                  5    \n",
       "3                                                  2    \n",
       "4                                                  2    \n",
       "\n",
       "   dataset_params.valid_dataloader_params.collate_fn  \\\n",
       "0  <super_gradients.training.utils.collate_fn.det...   \n",
       "1  <super_gradients.training.utils.collate_fn.det...   \n",
       "2  PPYoloECollateFN(random_resize_sizes=None, ran...   \n",
       "3  PPYoloECollateFN(random_resize_sizes=None, ran...   \n",
       "4  PPYoloECollateFN(random_resize_sizes=None, ran...   \n",
       "\n",
       "   additional_log_items.initial_LR.backbone  \\\n",
       "0                                      0.10   \n",
       "1                                      0.10   \n",
       "2                                      0.10   \n",
       "3                                      0.01   \n",
       "4                                      0.01   \n",
       "\n",
       "   additional_log_items.initial_LR.default  \n",
       "0                                     0.10  \n",
       "1                                     0.10  \n",
       "2                                     0.10  \n",
       "3                                     0.01  \n",
       "4                                     0.01  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_features = ['ckpt_name', 'Precision@0.50:0.95', 'Recall@0.50:0.95', 'mAP@0.50:0.95', 'F1@0.50:0.95', \n",
    "                'AP@0.50:0.95_Mass', 'AP@0.50:0.95_Calcification', 'Best_score_threshold',\n",
    "                'Best_score_threshold_Mass', 'Best_score_threshold_Calcification', 'Target']\n",
    "\n",
    "x = dataset.drop(columns=non_features)\n",
    "y = dataset['Target'] # this is stored in variable 'y' for later (training a ML model)\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_hyperparams.cosine_final_lr_ratio                 0\n",
      "training_hyperparams.optimizer                             0\n",
      "training_hyperparams.batch_accumulate                      0\n",
      "training_hyperparams.phase_callbacks                       0\n",
      "training_hyperparams.initial_lr.backbone                   0\n",
      "training_hyperparams.initial_lr.default                    0\n",
      "training_hyperparams.schema.properties.initial_lr.anyOf    0\n",
      "training_hyperparams.max_epochs                            0\n",
      "dataset_params.train_dataset_params                        0\n",
      "dataset_params.train_dataloader_params.batch_size          0\n",
      "dataset_params.train_dataloader_params.num_workers         0\n",
      "dataset_params.train_dataloader_params.collate_fn          0\n",
      "dataset_params.valid_dataset_params                        0\n",
      "dataset_params.valid_dataloader_params.batch_size          0\n",
      "dataset_params.valid_dataloader_params.num_workers         0\n",
      "dataset_params.valid_dataloader_params.collate_fn          0\n",
      "additional_log_items.initial_LR.backbone                   0\n",
      "additional_log_items.initial_LR.default                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericals = x.select_dtypes(include=['int64', 'float64']).columns\n",
    "categoricals = x.select_dtypes(include=['bool', 'object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing pipelines\n",
    "\n",
    "* StandardScaler for preprocessing numerical features so each will have a mean of 0 and a stardard deviation of 1. This helps avoiding bias. \n",
    "* OneHotEncoder converts categorical features into a format that can be provided to ML algorithms to do a better job in prediction. This transformation creates a binary column for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericals_transformer = StandardScaler()\n",
    "categoricals_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers= [\n",
    "        ('num', numericals_transformer, numericals),\n",
    "        ('cat', categoricals_transformer, categoricals)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline that includes PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3) # Define PCA instance\n",
    "\n",
    "# Chain preprocessing and PCA into a single workflow\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', pca)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data using the pipeline\n",
    "x_pca = pipeline.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PC1       PC2       PC3  Target\n",
      "0   4.720585  1.048849 -0.332982       0\n",
      "1   4.720585  1.048849 -0.332982       0\n",
      "2   3.128465 -1.283198 -1.209484       0\n",
      "3  -1.100292 -3.491603 -0.611232       0\n",
      "4  -1.221448 -3.661834 -0.149514       0\n",
      "5  -0.507832 -2.079319  1.182843       0\n",
      "6   0.789280  0.790011  3.532711       0\n",
      "7  -2.231871  1.348608  0.064315       1\n",
      "8  -2.231871  1.348608  0.064315       0\n",
      "9  -1.989559  1.689072 -0.859121       1\n",
      "10 -1.844171  1.893350 -1.413183       1\n",
      "11 -2.231871  1.348608  0.064315       0\n"
     ]
    }
   ],
   "source": [
    "pca_df = pd.DataFrame(data=x_pca, columns=['PC1', 'PC2', 'PC3'])\n",
    "pca_df['Target'] = y.values\n",
    "print(pca_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the number of principal components\n",
    "\n",
    "Explained Variance Ratio can help determine how many components to retain, since the purpose of PCA is reducing dimensions while preserving the most importnt variance in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Adam'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7828\\3708129766.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Plot cumulative explained variance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m plt.plot(range(1, len(pca.explained_variance_ratio_)+1),\n",
      "\u001b[1;32mc:\\Users\\sandra\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m             return_tuple = (\n",
      "\u001b[1;32mc:\\Users\\sandra\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1473\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\sandra\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[0mThis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mFortran\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mTo\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0mit\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m         \u001b[0mC\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m \u001b[1;34m'np.ascontiguousarray'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_is_centered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mU\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m             \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sandra\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[1;31m# written in a way to avoid the need for any inplace modification of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[1;31m# the input data contrary to the other solvers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[1;31m# The copy will happen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;31m# later, only if needed, once the solver negotiation below is done.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    512\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mforce_writeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sandra\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    629\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sandra\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1009\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m                 raise ValueError(\n\u001b[0;32m   1015\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m                 \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sandra\\.conda\\envs\\data_engineer\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    747\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2070\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Adam'"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "x_pca = pca.fit_transform(x)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_)+1),\n",
    "         np.cumsum(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance Ratio vs. Number of Components')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
